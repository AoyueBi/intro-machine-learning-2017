[
["solutions-nearest-neighbours.html", "D Solutions ch. 5 - Nearest neighbours D.1 Exercise 1", " D Solutions ch. 5 - Nearest neighbours Solutions to exercises of chapter 5. D.1 Exercise 1 Load libraries library(caret) ## Loading required package: lattice ## Loading required package: ggplot2 library(RColorBrewer) library(doMC) ## Loading required package: foreach ## Loading required package: iterators ## Loading required package: parallel library(corrplot) Prepare for parallel processing registerDoMC() Load data load(&quot;data/wheat_seeds/wheat_seeds.Rda&quot;) Partition data set.seed(42) trainIndex &lt;- createDataPartition(y=variety, times=1, p=0.7, list=F) varietyTrain &lt;- variety[trainIndex] morphTrain &lt;- morphometrics[trainIndex,] varietyTest &lt;- variety[-trainIndex] morphTest &lt;- morphometrics[-trainIndex,] summary(varietyTrain) ## Canadian Kama Rosa ## 49 49 49 summary(varietyTest) ## Canadian Kama Rosa ## 21 21 21 Data check: zero and near-zero predictors nzv &lt;- nearZeroVar(morphTrain, saveMetrics=T) nzv ## freqRatio percentUnique zeroVar nzv ## area 1.5 93.87755 FALSE FALSE ## perimeter 1.0 85.03401 FALSE FALSE ## compactness 1.0 93.19728 FALSE FALSE ## kernLength 1.5 91.83673 FALSE FALSE ## kernWidth 1.5 91.15646 FALSE FALSE ## asymCoef 1.0 98.63946 FALSE FALSE ## grooveLength 1.0 77.55102 FALSE FALSE Data check: are all predictors on same scale? summary(morphTrain) ## area perimeter compactness kernLength ## Min. :10.74 Min. :12.57 Min. :0.8081 Min. :4.902 ## 1st Qu.:12.28 1st Qu.:13.46 1st Qu.:0.8571 1st Qu.:5.253 ## Median :14.29 Median :14.28 Median :0.8735 Median :5.504 ## Mean :14.86 Mean :14.56 Mean :0.8712 Mean :5.632 ## 3rd Qu.:17.45 3rd Qu.:15.74 3rd Qu.:0.8880 3rd Qu.:5.979 ## Max. :21.18 Max. :17.25 Max. :0.9108 Max. :6.675 ## kernWidth asymCoef grooveLength ## Min. :2.630 Min. :0.7651 Min. :4.605 ## 1st Qu.:2.947 1st Qu.:2.5965 1st Qu.:5.028 ## Median :3.212 Median :3.5970 Median :5.222 ## Mean :3.258 Mean :3.6679 Mean :5.406 ## 3rd Qu.:3.563 3rd Qu.:4.6735 3rd Qu.:5.878 ## Max. :4.033 Max. :8.4560 Max. :6.550 featurePlot(x = morphTrain, y = varietyTrain, plot = &quot;box&quot;, ## Pass in options to bwplot() scales = list(y = list(relation=&quot;free&quot;), x = list(rot = 90)), layout = c(3,3)) Figure D.1: Boxplots of the 7 geometric parameters in the wheat data set Data check: pairwise correlations between predictors corMat &lt;- cor(morphTrain) corrplot(corMat, order=&quot;hclust&quot;, tl.cex=1) Figure D.2: Correlogram of the wheat seed data set. highCorr &lt;- findCorrelation(corMat, cutoff=0.75) length(highCorr) ## [1] 4 names(morphTrain)[highCorr] ## [1] &quot;area&quot; &quot;kernWidth&quot; &quot;perimeter&quot; &quot;kernLength&quot; Data check: skewness featurePlot(x = morphTrain, y = varietyTrain, plot = &quot;density&quot;, ## Pass in options to xyplot() to ## make it prettier scales = list(x = list(relation=&quot;free&quot;), y = list(relation=&quot;free&quot;)), adjust = 1.5, pch = &quot;|&quot;, layout = c(3, 3), auto.key = list(columns = 3)) Figure D.3: Density plots of the 7 geometric parameters in the wheat data set Create a ‘grid’ of values of k for evaluation: tuneParam &lt;- data.frame(k=seq(1,50,2)) Generate a list of seeds for reproducibility (optional) based on grid size set.seed(42) seeds &lt;- vector(mode = &quot;list&quot;, length = 101) for(i in 1:100) seeds[[i]] &lt;- sample.int(1000, length(tuneParam$k)) seeds[[101]] &lt;- sample.int(1000,1) Set training parameters. In the example in chapter 5 pre-processing was performed outside the cross-validation process to save time for the purposes of the demonstration. Here we have a relatively small data set, so we can do pre-processing within each iteration of the cross-validation process. We specify the option preProcOptions=list(cutoff=0.75) to set a value for the pairwise correlation coefficient cutoff. train_ctrl &lt;- trainControl(method=&quot;repeatedcv&quot;, number = 10, repeats = 10, preProcOptions=list(cutoff=0.75), seeds = seeds) Run training knnFit &lt;- train(morphTrain, varietyTrain, method=&quot;knn&quot;, preProcess = c(&quot;center&quot;, &quot;scale&quot;, &quot;corr&quot;), tuneGrid=tuneParam, trControl=train_ctrl) knnFit ## k-Nearest Neighbors ## ## 147 samples ## 7 predictor ## 3 classes: &#39;Canadian&#39;, &#39;Kama&#39;, &#39;Rosa&#39; ## ## Pre-processing: centered (3), scaled (3), remove (4) ## Resampling: Cross-Validated (10 fold, repeated 10 times) ## Summary of sample sizes: 133, 132, 132, 132, 132, 133, ... ## Resampling results across tuning parameters: ## ## k Accuracy Kappa ## 1 0.8478828 0.7715668 ## 3 0.9028425 0.8541302 ## 5 0.8858974 0.8286084 ## 7 0.8812308 0.8216084 ## 9 0.8766593 0.8147540 ## 11 0.8888022 0.8330012 ## 13 0.8982784 0.8472239 ## 15 0.8982784 0.8472239 ## 17 0.9002784 0.8502239 ## 19 0.8955641 0.8431552 ## 21 0.8935641 0.8401804 ## 23 0.8928974 0.8391804 ## 25 0.8922308 0.8381804 ## 27 0.8922308 0.8381804 ## 29 0.8915641 0.8371804 ## 31 0.8908022 0.8360588 ## 33 0.8874212 0.8309819 ## 35 0.8833260 0.8248032 ## 37 0.8854212 0.8279907 ## 39 0.8888498 0.8331446 ## 41 0.8888022 0.8330676 ## 43 0.8894689 0.8340676 ## 45 0.8901355 0.8350676 ## 47 0.8928498 0.8391362 ## 49 0.8908022 0.8360593 ## ## Accuracy was used to select the optimal model using the largest value. ## The final value used for the model was k = 3. Plot cross validation accuracy as a function of k plot(knnFit) Figure D.4: Accuracy (repeated cross-validation) as a function of neighbourhood size for the wheat seeds data set. Predict the class (wheat variety) of the observations in the test set. test_pred &lt;- predict(knnFit, morphTest) confusionMatrix(test_pred, varietyTest) ## Confusion Matrix and Statistics ## ## Reference ## Prediction Canadian Kama Rosa ## Canadian 18 4 0 ## Kama 3 16 2 ## Rosa 0 1 19 ## ## Overall Statistics ## ## Accuracy : 0.8413 ## 95% CI : (0.7274, 0.9212) ## No Information Rate : 0.3333 ## P-Value [Acc &gt; NIR] : &lt; 2.2e-16 ## ## Kappa : 0.7619 ## Mcnemar&#39;s Test P-Value : NA ## ## Statistics by Class: ## ## Class: Canadian Class: Kama Class: Rosa ## Sensitivity 0.8571 0.7619 0.9048 ## Specificity 0.9048 0.8810 0.9762 ## Pos Pred Value 0.8182 0.7619 0.9500 ## Neg Pred Value 0.9268 0.8810 0.9535 ## Prevalence 0.3333 0.3333 0.3333 ## Detection Rate 0.2857 0.2540 0.3016 ## Detection Prevalence 0.3492 0.3333 0.3175 ## Balanced Accuracy 0.8810 0.8214 0.9405 "]
]
