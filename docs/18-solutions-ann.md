# Solutions ch. 8 - Artificial neural networks {#solutions-ann}

Solutions to exercises of chapter \@ref(ann).

## Exercise 1


```r
library("neuralnet")
 
#To create a neural network to perform square root

#Generate 50 random numbers uniformly distributed between 0 and 100
#And store them as a dataframe
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
 
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Will have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```

```
## $call
## neuralnet(formula = Output ~ Input, data = trainingdata, hidden = 10, 
##     threshold = 0.01)
## 
## $response
##         Output
## 1  1.817237653
## 2  3.528134901
## 3  9.837937061
## 4  4.901081788
## 5  8.731865182
## 6  4.689839435
## 7  3.447894672
## 8  2.742642625
## 9  7.690043540
## 10 1.858314948
## 11 2.353882613
## 12 9.528645215
## 13 8.110937013
## 14 7.327526498
## 15 5.681370168
## 16 4.013783953
## 17 9.964433263
## 18 5.751253534
## 19 9.550548555
## 20 3.497103723
## 21 9.868111636
## 22 7.617300127
## 23 8.449064711
## 24 7.982566173
## 25 3.904900881
## 26 7.940854432
## 27 9.422492909
## 28 6.606389868
## 29 8.619729531
## 30 9.608989355
## 31 2.370430152
## 32 9.178254343
## 33 5.771093581
## 34 9.840721770
## 35 8.000301992
## 36 6.034697348
## 37 4.189529893
## 38 4.628917374
## 39 8.533979029
## 40 7.826627868
## 41 7.629444443
## 42 6.174876153
## 43 7.192929748
## 44 6.785396806
## 45 3.263541732
## 46 9.780667458
## 47 8.176936793
## 48 9.752944345
## 49 5.859570802
## 50 7.406422134
## 
## $covariate
##               [,1]
##  [1,]  3.302352689
##  [2,] 12.447735877
##  [3,] 96.785005624
##  [4,] 24.020602694
##  [5,] 76.245469553
##  [6,] 21.994593926
##  [7,] 11.887977668
##  [8,]  7.522088569
##  [9,] 59.136769641
## [10,]  3.453334444
## [11,]  5.540763354
## [12,] 90.795079642
## [13,] 65.787299233
## [14,] 53.692644578
## [15,] 32.277966989
## [16,] 16.110461624
## [17,] 99.289930263
## [18,] 33.076917217
## [19,] 91.212977702
## [20,] 12.229734450
## [21,] 97.379627265
## [22,] 58.023261232
## [23,] 71.386694489
## [24,] 63.721362711
## [25,] 15.248250891
## [26,] 63.057169109
## [27,] 88.783372613
## [28,] 43.644387089
## [29,] 74.299737182
## [30,] 92.332676426
## [31,]  5.618939106
## [32,] 84.240352781
## [33,] 33.305521123
## [34,] 96.839804947
## [35,] 64.004831971
## [36,] 36.417572084
## [37,] 17.552160728
## [38,] 21.426876052
## [39,] 72.828798066
## [40,] 61.256103776
## [41,] 58.208422503
## [42,] 38.129095500
## [43,] 51.738238358
## [44,] 46.041609813
## [45,] 10.650704638
## [46,] 95.661455928
## [47,] 66.862295312
## [48,] 95.119923400
## [49,] 34.334569983
## [50,] 54.855088820
## 
## $model.list
## $model.list$response
## [1] "Output"
## 
## $model.list$variables
## [1] "Input"
## 
## 
## $err.fct
## function (x, y) 
## {
##     1/2 * (y - x)^2
## }
## <environment: 0x7fede91dd510>
## attr(,"type")
## [1] "sse"
## 
## $act.fct
## function (x) 
## {
##     1/(1 + exp(-x))
## }
## <environment: 0x7fede91dd510>
## attr(,"type")
## [1] "logistic"
## 
## $linear.output
## [1] TRUE
## 
## $data
##           Input      Output
## 1   3.302352689 1.817237653
## 2  12.447735877 3.528134901
## 3  96.785005624 9.837937061
## 4  24.020602694 4.901081788
## 5  76.245469553 8.731865182
## 6  21.994593926 4.689839435
## 7  11.887977668 3.447894672
## 8   7.522088569 2.742642625
## 9  59.136769641 7.690043540
## 10  3.453334444 1.858314948
## 11  5.540763354 2.353882613
## 12 90.795079642 9.528645215
## 13 65.787299233 8.110937013
## 14 53.692644578 7.327526498
## 15 32.277966989 5.681370168
## 16 16.110461624 4.013783953
## 17 99.289930263 9.964433263
## 18 33.076917217 5.751253534
## 19 91.212977702 9.550548555
## 20 12.229734450 3.497103723
## 21 97.379627265 9.868111636
## 22 58.023261232 7.617300127
## 23 71.386694489 8.449064711
## 24 63.721362711 7.982566173
## 25 15.248250891 3.904900881
## 26 63.057169109 7.940854432
## 27 88.783372613 9.422492909
## 28 43.644387089 6.606389868
## 29 74.299737182 8.619729531
## 30 92.332676426 9.608989355
## 31  5.618939106 2.370430152
## 32 84.240352781 9.178254343
## 33 33.305521123 5.771093581
## 34 96.839804947 9.840721770
## 35 64.004831971 8.000301992
## 36 36.417572084 6.034697348
## 37 17.552160728 4.189529893
## 38 21.426876052 4.628917374
## 39 72.828798066 8.533979029
## 40 61.256103776 7.826627868
## 41 58.208422503 7.629444443
## 42 38.129095500 6.174876153
## 43 51.738238358 7.192929748
## 44 46.041609813 6.785396806
## 45 10.650704638 3.263541732
## 46 95.661455928 9.780667458
## 47 66.862295312 8.176936793
## 48 95.119923400 9.752944345
## 49 34.334569983 5.859570802
## 50 54.855088820 7.406422134
## 
## $net.result
## $net.result[[1]]
##           [,1]
## 1  1.810565928
## 2  3.531596024
## 3  9.833307083
## 4  4.898350058
## 5  8.738318698
## 6  4.685196879
## 7  3.451700517
## 8  2.735797051
## 9  7.685970313
## 10 1.867319915
## 11 2.354266740
## 12 9.534809639
## 13 8.109838824
## 14 7.323286983
## 15 5.685801481
## 16 4.011210241
## 17 9.952483860
## 18 5.755889007
## 19 9.556230670
## 20 3.500739062
## 21 9.861907991
## 22 7.613011540
## 23 8.451961510
## 24 7.980269682
## 25 3.903810955
## 26 7.938219662
## 27 9.430488055
## 28 6.606963682
## 29 8.624817003
## 30 9.613194049
## 31 2.369831658
## 32 9.187806231
## 33 5.775768813
## 34 9.835950899
## 35 7.998157254
## 36 6.039160578
## 37 4.185059462
## 38 4.623891314
## 39 8.537971113
## 40 7.823207349
## 41 7.625185357
## 42 6.178721741
## 43 7.189173385
## 44 6.784418507
## 45 3.266657220
## 46 9.778745442
## 47 8.176537573
## 48 9.752207334
## 49 5.864325930
## 50 7.402029443
## 
## 
## $weights
## $weights[[1]]
## $weights[[1]][[1]]
##                [,1]           [,2]         [,3]          [,4]         [,5]
## [1,] -0.09905182018  1.52556148210  0.384801319  1.7898341754 -3.928610598
## [2,] -0.17440261350 -0.03695692349 -2.181438072 -0.3523692229  2.135867441
##                [,6]         [,7]           [,8]          [,9]
## [1,] -2.89752315751  1.626354590 -0.22970529300 -1.3238708728
## [2,]  0.03240745843 -2.027030662  0.03914190882  0.1039313114
##               [,10]
## [1,]  0.33544748981
## [2,] -0.04385205118
## 
## $weights[[1]][[2]]
##                [,1]
##  [1,]  1.1683448323
##  [2,] -1.1286139948
##  [3,] -2.1344848953
##  [4,]  1.4983542519
##  [5,] -0.6741642747
##  [6,]  2.7298003120
##  [7,]  4.4941797126
##  [8,]  1.7872655617
##  [9,]  2.3669073656
## [10,]  1.4066130695
## [11,] -2.2276141769
## 
## 
## 
## $startweights
## $startweights[[1]]
## $startweights[[1]][[1]]
##              [,1]          [,2]          [,3]         [,4]         [,5]
## [1,] 0.6001088465  0.6533812051  0.2692267459  1.554724273 0.7412664578
## [2,] 0.1056782656 -0.9166592787 -1.5284650915 -1.255078652 2.6596810568
##               [,6]         [,7]          [,8]         [,9]       [,10]
## [1,] -1.3456271147  1.059907735 -0.2995680512 0.8657378529 1.160079713
## [2,]  0.8456128252 -1.359482510 -0.6385699288 1.6957842681 1.058593873
## 
## $startweights[[1]][[2]]
##                [,1]
##  [1,] -0.5117270120
##  [2,] -0.5914039497
##  [3,] -1.4547487374
##  [4,]  1.3827681568
##  [5,] -0.5215139452
##  [6,]  1.0497284642
##  [7,] -0.7600186020
##  [8,]  0.7877169193
##  [9,]  0.5285968958
## [10,] -0.2757566037
## [11,] -2.6200917106
## 
## 
## 
## $generalized.weights
## $generalized.weights[[1]]
##                [,1]
## 1  -0.2750640665056
## 2  -0.0157497550192
## 3  -0.0005556049682
## 4  -0.0053992279031
## 5  -0.0008566827552
## 6  -0.0062182304372
## 7  -0.0171007684608
## 8  -0.0389237762994
## 9  -0.0012698068150
## 10 -0.2164417108377
## 11 -0.0625336619715
## 12 -0.0006311659650
## 13 -0.0010800195075
## 14 -0.0014697552010
## 15 -0.0033152537977
## 16 -0.0101810435963
## 17 -0.0005262270283
## 18 -0.0031828837357
## 19 -0.0006256304858
## 20 -0.0162531517752
## 21 -0.0005485198543
## 22 -0.0013068350243
## 23 -0.0009516573294
## 24 -0.0011339170843
## 25 -0.0111349285863
## 26 -0.0011521312135
## 27 -0.0006584207309
## 28 -0.0020251591447
## 29 -0.0008931705732
## 30 -0.0006110038143
## 31 -0.0612490464869
## 32 -0.0007240401312
## 33 -0.0031465913950
## 34 -0.0005549490558
## 35 -0.0011262798159
## 36 -0.0027136751220
## 37 -0.0088781042757
## 38 -0.0064818818336
## 39 -0.0009220874771
## 40 -0.0012039140053
## 41 -0.0013005544595
## 42 -0.0025167492140
## 43 -0.0015551279641
## 44 -0.0018618520158
## 45 -0.0208943399928
## 46 -0.0005691876782
## 47 -0.0010534973366
## 48 -0.0005758274392
## 49 -0.0029913615906
## 50 -0.0014227488716
## 
## 
## $result.matrix
##                                         1
## error                     0.0005625472702
## reached.threshold         0.0087190494651
## steps                  2430.0000000000000
## Intercept.to.1layhid1    -0.0990518201772
## Input.to.1layhid1        -0.1744026134981
## Intercept.to.1layhid2     1.5255614820962
## Input.to.1layhid2        -0.0369569234908
## Intercept.to.1layhid3     0.3848013189806
## Input.to.1layhid3        -2.1814380719751
## Intercept.to.1layhid4     1.7898341753972
## Input.to.1layhid4        -0.3523692229014
## Intercept.to.1layhid5    -3.9286105982335
## Input.to.1layhid5         2.1358674406132
## Intercept.to.1layhid6    -2.8975231575076
## Input.to.1layhid6         0.0324074584311
## Intercept.to.1layhid7     1.6263545904959
## Input.to.1layhid7        -2.0270306619174
## Intercept.to.1layhid8    -0.2297052929994
## Input.to.1layhid8         0.0391419088175
## Intercept.to.1layhid9    -1.3238708728427
## Input.to.1layhid9         0.1039313113905
## Intercept.to.1layhid10    0.3354474898105
## Input.to.1layhid10       -0.0438520511841
## Intercept.to.Output       1.1683448322701
## 1layhid.1.to.Output      -1.1286139948433
## 1layhid.2.to.Output      -2.1344848953199
## 1layhid.3.to.Output       1.4983542518614
## 1layhid.4.to.Output      -0.6741642746723
## 1layhid.5.to.Output       2.7298003120154
## 1layhid.6.to.Output       4.4941797125653
## 1layhid.7.to.Output       1.7872655617261
## 1layhid.8.to.Output       2.3669073655738
## 1layhid.9.to.Output       1.4066130695260
## 1layhid.10.to.Output     -2.2276141768997
## 
## attr(,"class")
## [1] "nn"
```

```r
#Plot the neural network
plot(net.sqrt)
 
#Test the neural network on some training data
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
 
#See what properties net.sqrt has
ls(net.results)
```

```
## [1] "net.result" "neurons"
```

```r
#see the results
print(net.results$net.result)
```

```
##                [,1]
##  [1,] 0.07312097566
##  [2,] 2.02589427772
##  [3,] 2.99854376399
##  [4,] 3.99760481519
##  [5,] 4.99835911768
##  [6,] 6.00456611888
##  [7,] 6.99735852485
##  [8,] 7.99785263859
##  [9,] 9.00896632359
## [10,] 9.98563575809
```

```r
#Display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
                         as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```

```
##    Input Expected Output Neural Net Output
## 1      1               1     0.07312097566
## 2      4               2     2.02589427772
## 3      9               3     2.99854376399
## 4     16               4     3.99760481519
## 5     25               5     4.99835911768
## 6     36               6     6.00456611888
## 7     49               7     6.99735852485
## 8     64               8     7.99785263859
## 9     81               9     9.00896632359
## 10   100              10     9.98563575809
```

*Acknowledgement: this example excercise was from* http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/ 

