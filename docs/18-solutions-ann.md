# Solutions ch. 8 - Artificial neural networks {#solutions-ann}

Solutions to exercises of chapter \@ref(ann).

## Exercise 1


```r
library("neuralnet")
 
#To create a neural network to perform square root

#Generate 50 random numbers uniformly distributed between 0 and 100
#And store them as a dataframe
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
 
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Will have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```

```
## $call
## neuralnet(formula = Output ~ Input, data = trainingdata, hidden = 10, 
##     threshold = 0.01)
## 
## $response
##         Output
## 1  9.483072033
## 2  7.846269713
## 3  9.313663520
## 4  7.025071829
## 5  4.786830886
## 6  7.889343778
## 7  5.093381138
## 8  5.486730402
## 9  8.456943573
## 10 3.309599972
## 11 4.839584774
## 12 8.675420581
## 13 7.228396423
## 14 2.274766998
## 15 8.097979527
## 16 9.012316747
## 17 8.060115183
## 18 8.056632727
## 19 4.701449178
## 20 7.515900911
## 21 9.396624473
## 22 3.893913306
## 23 2.729570899
## 24 6.628978930
## 25 1.967114937
## 26 3.793746011
## 27 7.666558766
## 28 9.030826412
## 29 7.679288939
## 30 6.235186484
## 31 6.530604361
## 32 9.580464194
## 33 7.236326716
## 34 7.560434447
## 35 2.580654861
## 36 9.029978797
## 37 6.497043776
## 38 7.451527043
## 39 5.077881374
## 40 8.903347512
## 41 8.818477905
## 42 4.453039474
## 43 4.394978858
## 44 9.106064206
## 45 6.568643711
## 46 2.646365994
## 47 9.507547754
## 48 6.864778166
## 49 9.145942479
## 50 7.556241428
## 
## $covariate
##               [,1]
##  [1,] 89.928655187
##  [2,] 61.563948402
##  [3,] 86.744328169
##  [4,] 49.351634202
##  [5,] 22.913749935
##  [6,] 62.241745251
##  [7,] 25.942531414
##  [8,] 30.104210507
##  [9,] 71.519894595
## [10,] 10.953451972
## [11,] 23.421580787
## [12,] 75.262922258
## [13,] 52.249714849
## [14,]  5.174564896
## [15,] 65.577272419
## [16,] 81.221853150
## [17,] 64.965456771
## [18,] 64.909330895
## [19,] 22.103624372
## [20,] 56.488766498
## [21,] 88.296551490
## [22,] 15.162560833
## [23,]  7.450557291
## [24,] 43.943361659
## [25,]  3.869541176
## [26,] 14.392508799
## [27,] 58.776123310
## [28,] 81.555825681
## [29,] 58.971478604
## [30,] 38.877550489
## [31,] 42.648793315
## [32,] 91.785294167
## [33,] 52.364424337
## [34,] 57.160169026
## [35,]  6.659779511
## [36,] 81.540517067
## [37,] 42.211577832
## [38,] 55.525255273
## [39,] 25.784879248
## [40,] 79.269596911
## [41,] 77.765552560
## [42,] 19.829560560
## [43,] 19.315839163
## [44,] 82.920405315
## [45,] 43.147080205
## [46,]  7.003252977
## [47,] 90.393464291
## [48,] 47.125179274
## [49,] 83.648263826
## [50,] 57.096784515
## 
## $model.list
## $model.list$response
## [1] "Output"
## 
## $model.list$variables
## [1] "Input"
## 
## 
## $err.fct
## function (x, y) 
## {
##     1/2 * (y - x)^2
## }
## <environment: 0x7fb7aae33510>
## attr(,"type")
## [1] "sse"
## 
## $act.fct
## function (x) 
## {
##     1/(1 + exp(-x))
## }
## <environment: 0x7fb7aae33510>
## attr(,"type")
## [1] "logistic"
## 
## $linear.output
## [1] TRUE
## 
## $data
##           Input      Output
## 1  89.928655187 9.483072033
## 2  61.563948402 7.846269713
## 3  86.744328169 9.313663520
## 4  49.351634202 7.025071829
## 5  22.913749935 4.786830886
## 6  62.241745251 7.889343778
## 7  25.942531414 5.093381138
## 8  30.104210507 5.486730402
## 9  71.519894595 8.456943573
## 10 10.953451972 3.309599972
## 11 23.421580787 4.839584774
## 12 75.262922258 8.675420581
## 13 52.249714849 7.228396423
## 14  5.174564896 2.274766998
## 15 65.577272419 8.097979527
## 16 81.221853150 9.012316747
## 17 64.965456771 8.060115183
## 18 64.909330895 8.056632727
## 19 22.103624372 4.701449178
## 20 56.488766498 7.515900911
## 21 88.296551490 9.396624473
## 22 15.162560833 3.893913306
## 23  7.450557291 2.729570899
## 24 43.943361659 6.628978930
## 25  3.869541176 1.967114937
## 26 14.392508799 3.793746011
## 27 58.776123310 7.666558766
## 28 81.555825681 9.030826412
## 29 58.971478604 7.679288939
## 30 38.877550489 6.235186484
## 31 42.648793315 6.530604361
## 32 91.785294167 9.580464194
## 33 52.364424337 7.236326716
## 34 57.160169026 7.560434447
## 35  6.659779511 2.580654861
## 36 81.540517067 9.029978797
## 37 42.211577832 6.497043776
## 38 55.525255273 7.451527043
## 39 25.784879248 5.077881374
## 40 79.269596911 8.903347512
## 41 77.765552560 8.818477905
## 42 19.829560560 4.453039474
## 43 19.315839163 4.394978858
## 44 82.920405315 9.106064206
## 45 43.147080205 6.568643711
## 46  7.003252977 2.646365994
## 47 90.393464291 9.507547754
## 48 47.125179274 6.864778166
## 49 83.648263826 9.145942479
## 50 57.096784515 7.556241428
## 
## $net.result
## $net.result[[1]]
##           [,1]
## 1  9.469088676
## 2  7.846518475
## 3  9.311037206
## 4  7.017065592
## 5  4.782863131
## 6  7.890501820
## 7  5.099535786
## 8  5.502462621
## 9  8.468822113
## 10 3.325831485
## 11 4.837214580
## 12 8.688755935
## 13 7.220158403
## 14 2.264838656
## 15 8.103609850
## 16 9.021825700
## 17 8.064943714
## 18 8.061386969
## 19 4.695201483
## 20 7.510204453
## 21 9.388881875
## 22 3.895872918
## 23 2.728768408
## 24 6.626430677
## 25 1.978880683
## 26 3.799389632
## 27 7.663280716
## 28 9.039854491
## 29 7.676241400
## 30 6.242402310
## 31 6.530261992
## 32 9.558276359
## 33 7.228115666
## 34 7.555387938
## 35 2.573890084
## 36 9.039029591
## 37 6.497507562
## 38 7.445000965
## 39 5.083518065
## 40 8.915068527
## 41 8.831240867
## 42 4.443288718
## 43 4.385225216
## 44 9.112802331
## 45 6.567418383
## 46 2.642058554
## 47 9.491622010
## 48 6.858224085
## 49 9.151239713
## 50 7.551131225
## 
## 
## $weights
## $weights[[1]]
## $weights[[1]][[1]]
##                [,1]          [,2]         [,3]           [,4]
## [1,] -0.56228647539  0.7414165142 2.2165096733 -1.20082859008
## [2,]  0.02335861312 -0.2489967206 0.1030311534  0.02363943764
##                [,5]           [,6]           [,7]          [,8]
## [1,]  0.77076957441  0.31513149392 -0.37889243418  3.3096848554
## [2,] -0.02357955122 -0.02164765453  0.02243225481 -0.1598179903
##             [,9]          [,10]
## [1,] 6.114495982 -0.68532049741
## [2,] 8.037406262  0.02378908859
## 
## $weights[[1]][[2]]
##                [,1]
##  [1,]  1.1777759998
##  [2,]  1.8206731018
##  [3,] -2.2876504417
##  [4,]  1.5378552685
##  [5,]  3.7292872867
##  [6,] -1.6305658641
##  [7,] -0.7376184241
##  [8,]  0.9463030976
##  [9,] -0.8131590711
## [10,] -0.6695200710
## [11,]  3.5995697029
## 
## 
## 
## $startweights
## $startweights[[1]]
## $startweights[[1]][[1]]
##               [,1]          [,2]          [,3]           [,4]
## [1,] -0.1390156029 -0.2825838106  0.5717457335 -0.83235666421
## [2,]  0.1545760253 -1.6985697571 -0.4115277062  0.04087815712
##                [,5]          [,6]         [,7]          [,8]          [,9]
## [1,]  0.06445214763 -0.6521752853 0.2108474730  2.1639246851 -0.8192107729
## [2,] -0.30904112467 -0.7833122859 0.1987018776 -0.6064693532  0.9077505310
##              [,10]
## [1,] -0.2391340158
## [2,]  0.1387206037
## 
## $startweights[[1]][[2]]
##                  [,1]
##  [1,]  0.565285213643
##  [2,]  0.057846366312
##  [3,] -0.148026030610
##  [4,]  1.326896518182
##  [5,]  0.370189434967
##  [6,] -1.057485986668
##  [7,] -0.307460945598
##  [8,]  0.005152731432
##  [9,]  0.200225553559
## [10,] -1.282010857159
## [11,]  2.071287243236
## 
## 
## 
## $generalized.weights
## $generalized.weights[[1]]
##                [,1]
## 1  -0.0006063513305
## 2  -0.0012110150474
## 3  -0.0006544001624
## 4  -0.0016762841103
## 5  -0.0059410390248
## 6  -0.0011904716083
## 7  -0.0048518352124
## 8  -0.0037225872441
## 9  -0.0009458529040
## 10 -0.0195525774655
## 11 -0.0057407629934
## 12 -0.0008633137563
## 13 -0.0015451922568
## 14 -0.0750243551305
## 15 -0.0010951303110
## 16 -0.0007473340892
## 17 -0.0011119387027
## 18 -0.0011134953317
## 19 -0.0062773660469
## 20 -0.0013795792756
## 21 -0.0006305045410
## 22 -0.0109645740218
## 23 -0.0405273234348
## 24 -0.0019804555700
## 25 -0.1147613539687
## 26 -0.0119400592521
## 27 -0.0013001702392
## 28 -0.0007413401283
## 29 -0.0012936633643
## 30 -0.0023867968821
## 31 -0.0020698629416
## 32 -0.0005800333077
## 33 -0.0015403390118
## 34 -0.0013556305306
## 35 -0.0494747152759
## 36 -0.0007416137748
## 37 -0.0021019801176
## 38 -0.0014149478796
## 39 -0.0049026247216
## 40 -0.0007834049758
## 41 -0.0008124426365
## 42 -0.0073601299207
## 43 -0.0076422173372
## 44 -0.0007173673059
## 45 -0.0020344826368
## 46 -0.0452903633016
## 47 -0.0005996491168
## 48 -0.0017902643735
## 49 -0.0007049129578
## 50 -0.0013578678517
## 
## 
## $result.matrix
##                                        1
## error                     0.001826056050
## reached.threshold         0.009123223744
## steps                  3395.000000000000
## Intercept.to.1layhid1    -0.562286475394
## Input.to.1layhid1         0.023358613121
## Intercept.to.1layhid2     0.741416514231
## Input.to.1layhid2        -0.248996720573
## Intercept.to.1layhid3     2.216509673274
## Input.to.1layhid3         0.103031153386
## Intercept.to.1layhid4    -1.200828590082
## Input.to.1layhid4         0.023639437641
## Intercept.to.1layhid5     0.770769574408
## Input.to.1layhid5        -0.023579551217
## Intercept.to.1layhid6     0.315131493925
## Input.to.1layhid6        -0.021647654534
## Intercept.to.1layhid7    -0.378892434185
## Input.to.1layhid7         0.022432254811
## Intercept.to.1layhid8     3.309684855358
## Input.to.1layhid8        -0.159817990291
## Intercept.to.1layhid9     6.114495981506
## Input.to.1layhid9         8.037406261754
## Intercept.to.1layhid10   -0.685320497414
## Input.to.1layhid10        0.023789088594
## Intercept.to.Output       1.177775999840
## 1layhid.1.to.Output       1.820673101810
## 1layhid.2.to.Output      -2.287650441717
## 1layhid.3.to.Output       1.537855268487
## 1layhid.4.to.Output       3.729287286669
## 1layhid.5.to.Output      -1.630565864139
## 1layhid.6.to.Output      -0.737618424077
## 1layhid.7.to.Output       0.946303097561
## 1layhid.8.to.Output      -0.813159071113
## 1layhid.9.to.Output      -0.669520070962
## 1layhid.10.to.Output      3.599569702901
## 
## attr(,"class")
## [1] "nn"
```

```r
#Plot the neural network
plot(net.sqrt)
 
#Test the neural network on some training data
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
 
#See what properties net.sqrt has
ls(net.results)
```

```
## [1] "net.result" "neurons"
```

```r
#see the results
print(net.results$net.result)
```

```
##              [,1]
##  [1,] 1.344072846
##  [2,] 2.007853229
##  [3,] 3.010426561
##  [4,] 3.998200778
##  [5,] 5.002983351
##  [6,] 6.012799956
##  [7,] 6.992147519
##  [8,] 8.003537819
##  [9,] 9.009811478
## [10,] 9.926695845
```

```r
#Display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
                         as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```

```
##    Input Expected Output Neural Net Output
## 1      1               1       1.344072846
## 2      4               2       2.007853229
## 3      9               3       3.010426561
## 4     16               4       3.998200778
## 5     25               5       5.002983351
## 6     36               6       6.012799956
## 7     49               7       6.992147519
## 8     64               8       8.003537819
## 9     81               9       9.009811478
## 10   100              10       9.926695845
```

*Acknowledgement: this example excercise was from* http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/ 

