# Solutions ch. 8 - Artificial neural networks {#solutions-ann}

Solutions to exercises of chapter \@ref(ann).

## Exercise 1


```r
library("neuralnet")
 
#To create a neural network to perform square root

#Generate 50 random numbers uniformly distributed between 0 and 100
#And store them as a dataframe
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
 
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Will have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```

```
## $call
## neuralnet(formula = Output ~ Input, data = trainingdata, hidden = 10, 
##     threshold = 0.01)
## 
## $response
##         Output
## 1  8.428772560
## 2  8.029796420
## 3  5.856305540
## 4  7.555908344
## 5  9.525634958
## 6  7.317011347
## 7  6.906226187
## 8  7.924266742
## 9  9.715755089
## 10 3.530011111
## 11 9.823076998
## 12 9.603888554
## 13 8.590910395
## 14 8.431439250
## 15 9.579511816
## 16 8.392750012
## 17 7.750202042
## 18 9.425718061
## 19 8.016751876
## 20 5.828198145
## 21 6.433508654
## 22 7.401953817
## 23 6.665349731
## 24 6.525100208
## 25 3.063701307
## 26 7.901156317
## 27 7.744635670
## 28 4.020356421
## 29 5.024343445
## 30 9.106812710
## 31 7.860550621
## 32 8.772433980
## 33 7.279925992
## 34 5.186187780
## 35 1.302621123
## 36 9.743955526
## 37 2.768690743
## 38 8.437758243
## 39 9.487366407
## 40 6.547771051
## 41 1.754113962
## 42 9.727944096
## 43 5.358272850
## 44 1.275396380
## 45 7.469165221
## 46 4.546917508
## 47 6.127429355
## 48 5.596765067
## 49 5.630584867
## 50 8.992673715
## 
## $covariate
##               [,1]
##  [1,] 71.044206875
##  [2,] 64.477630542
##  [3,] 34.296314581
##  [4,] 57.091750903
##  [5,] 90.737721347
##  [6,] 53.538655047
##  [7,] 47.695960151
##  [8,] 62.794003403
##  [9,] 94.395896955
## [10,] 12.460978446
## [11,] 96.492841700
## [12,] 92.234675353
## [13,] 73.803741415
## [14,] 71.089167823
## [15,] 91.767046624
## [16,] 70.438252762
## [17,] 60.065631685
## [18,] 88.844160968
## [19,] 64.268310647
## [20,] 33.967893617
## [21,] 41.390033602
## [22,] 54.788920307
## [23,] 44.426887040
## [24,] 42.576932721
## [25,]  9.386265697
## [26,] 62.428271142
## [27,] 59.979381668
## [28,] 16.163265752
## [29,] 25.244027050
## [30,] 82.934037736
## [31,] 61.788256071
## [32,] 76.955597941
## [33,] 52.997322450
## [34,] 26.896543684
## [35,]  1.696821791
## [36,] 94.944669283
## [37,]  7.665648428
## [38,] 71.195764164
## [39,] 90.010121348
## [40,] 42.873305734
## [41,]  3.076915792
## [42,] 94.632896339
## [43,] 28.711087932
## [44,]  1.626635925
## [45,] 55.788429105
## [46,] 20.674458821
## [47,] 37.545390497
## [48,] 31.323779211
## [49,] 31.703485944
## [50,] 80.868180539
## 
## $model.list
## $model.list$response
## [1] "Output"
## 
## $model.list$variables
## [1] "Input"
## 
## 
## $err.fct
## function (x, y) 
## {
##     1/2 * (y - x)^2
## }
## <environment: 0x7fee330d1b58>
## attr(,"type")
## [1] "sse"
## 
## $act.fct
## function (x) 
## {
##     1/(1 + exp(-x))
## }
## <environment: 0x7fee330d1b58>
## attr(,"type")
## [1] "logistic"
## 
## $linear.output
## [1] TRUE
## 
## $data
##           Input      Output
## 1  71.044206875 8.428772560
## 2  64.477630542 8.029796420
## 3  34.296314581 5.856305540
## 4  57.091750903 7.555908344
## 5  90.737721347 9.525634958
## 6  53.538655047 7.317011347
## 7  47.695960151 6.906226187
## 8  62.794003403 7.924266742
## 9  94.395896955 9.715755089
## 10 12.460978446 3.530011111
## 11 96.492841700 9.823076998
## 12 92.234675353 9.603888554
## 13 73.803741415 8.590910395
## 14 71.089167823 8.431439250
## 15 91.767046624 9.579511816
## 16 70.438252762 8.392750012
## 17 60.065631685 7.750202042
## 18 88.844160968 9.425718061
## 19 64.268310647 8.016751876
## 20 33.967893617 5.828198145
## 21 41.390033602 6.433508654
## 22 54.788920307 7.401953817
## 23 44.426887040 6.665349731
## 24 42.576932721 6.525100208
## 25  9.386265697 3.063701307
## 26 62.428271142 7.901156317
## 27 59.979381668 7.744635670
## 28 16.163265752 4.020356421
## 29 25.244027050 5.024343445
## 30 82.934037736 9.106812710
## 31 61.788256071 7.860550621
## 32 76.955597941 8.772433980
## 33 52.997322450 7.279925992
## 34 26.896543684 5.186187780
## 35  1.696821791 1.302621123
## 36 94.944669283 9.743955526
## 37  7.665648428 2.768690743
## 38 71.195764164 8.437758243
## 39 90.010121348 9.487366407
## 40 42.873305734 6.547771051
## 41  3.076915792 1.754113962
## 42 94.632896339 9.727944096
## 43 28.711087932 5.358272850
## 44  1.626635925 1.275396380
## 45 55.788429105 7.469165221
## 46 20.674458821 4.546917508
## 47 37.545390497 6.127429355
## 48 31.323779211 5.596765067
## 49 31.703485944 5.630584867
## 50 80.868180539 8.992673715
## 
## $net.result
## $net.result[[1]]
##           [,1]
## 1  8.431463984
## 2  8.027344142
## 3  5.860875764
## 4  7.551098679
## 5  9.528459572
## 6  7.313056845
## 7  6.906183452
## 8  7.920845461
## 9  9.711047573
## 10 3.543437735
## 11 9.812454867
## 12 9.604038724
## 13 8.595889687
## 14 8.434168942
## 15 9.580556164
## 16 8.394925179
## 17 7.745715177
## 18 9.431172798
## 19 8.014167901
## 20 5.832486478
## 21 6.438451761
## 22 7.397545439
## 23 6.668100688
## 24 6.529280035
## 25 3.066385091
## 26 7.897553746
## 27 7.740126558
## 28 4.024687001
## 29 5.016289078
## 30 9.115805338
## 31 7.856658172
## 32 8.779648217
## 33 7.276217161
## 34 5.180326631
## 35 1.303194110
## 36 9.737817735
## 37 2.754934617
## 38 8.440578619
## 39 9.491298047
## 40 6.551738552
## 41 1.758678792
## 42 9.722628920
## 43 5.355328551
## 44 1.274120212
## 45 7.464512359
## 46 4.538940898
## 47 6.133441328
## 48 5.597940281
## 49 5.632290512
## 50 9.001534061
## 
## 
## $weights
## $weights[[1]]
## $weights[[1]][[1]]
##                [,1]          [,2]           [,3]          [,4]
## [1,]  3.34352311047 -1.0238568833 -0.82976248138 -1.9300149280
## [2,] -0.03266490281  0.0265849497  0.03334361268  0.1039925331
##                [,5]           [,6]           [,7]          [,8]
## [1,] -1.30977664282  1.91336282932 -1.56719892181  0.3673678602
## [2,]  0.02511026399 -0.04163495553  0.02522654985 -0.2266382104
##                [,9]        [,10]
## [1,] -1.00275731688 -25.52190594
## [2,]  0.02616244916  13.97918808
## 
## $weights[[1]][[2]]
##                [,1]
##  [1,]  0.3631573093
##  [2,] -0.8769227235
##  [3,]  1.4150924807
##  [4,]  1.8162786097
##  [5,]  1.5621092894
##  [6,]  1.6850193729
##  [7,]  0.5464951292
##  [8,]  2.9640115779
##  [9,] -2.9564849836
## [10,]  2.4067860122
## [11,]  0.1486939056
## 
## 
## 
## $startweights
## $startweights[[1]]
## $startweights[[1]][[1]]
##               [,1]         [,2]        [,3]         [,4]          [,5]
## [1,]  1.7218847402 0.5989721329 0.544075034 0.5875493748 0.07632271556
## [2,] -0.4127041854 1.9318927700 1.345629931 2.0796520976 1.36470279928
##              [,6]          [,7]          [,8]          [,9]         [,10]
## [1,] -1.122681198 -0.4783376653  1.5130243754 -0.5323985197 -0.3022361852
## [2,] -0.580312476  1.0771602833 -0.3193687816  0.1830770937  0.9856779130
## 
## $startweights[[1]][[2]]
##                 [,1]
##  [1,]  0.08257727235
##  [2,] -0.55424935227
##  [3,]  0.99259717829
##  [4,]  1.47859036927
##  [5,]  1.28481961317
##  [6,]  0.55359738433
##  [7,] -0.68907764090
##  [8,]  0.73697173728
##  [9,]  1.20086321821
## [10,] -0.09320826895
## [11,] -0.25036955618
## 
## 
## 
## $generalized.weights
## $generalized.weights[[1]]
##                [,1]
## 1  -0.0009603205041
## 2  -0.0011151094686
## 3  -0.0030256764885
## 4  -0.0013366976939
## 5  -0.0006261577209
## 6  -0.0014708737365
## 7  -0.0017542712886
## 8  -0.0011603305281
## 9  -0.0005784238324
## 10 -0.0156948213616
## 11 -0.0005526113964
## 12 -0.0006061940627
## 13 -0.0009034943960
## 14 -0.0009593603462
## 15 -0.0006123649103
## 16 -0.0009733783664
## 17 -0.0012397358669
## 18 -0.0006523082393
## 19 -0.0011205899467
## 20 -0.0030755585055
## 21 -0.0022030864092
## 22 -0.0014210293658
## 23 -0.0019628868131
## 24 -0.0021030243839
## 25 -0.0269590817517
## 26 -0.0011705132580
## 27 -0.0012423839047
## 28 -0.0099263057617
## 29 -0.0049939350066
## 30 -0.0007409875656
## 31 -0.0011886616378
## 32 -0.0008433486399
## 33 -0.0014934522210
## 34 -0.0045217248410
## 35 -1.2410626327135
## 36 -0.0005715634003
## 37 -0.0396103745307
## 38 -0.0009570886886
## 39 -0.0006360850143
## 40 -0.0020793344381
## 41 -0.1769942781412
## 42 -0.0005754517073
## 43 -0.0040716895622
## 44 -1.0065660716448
## 45 -0.0013833125199
## 46 -0.0067581476129
## 47 -0.0025941540913
## 48 -0.0035263816984
## 49 -0.0034558849851
## 50 -0.0007747820839
## 
## 
## $result.matrix
##                                          1
## error                      0.0007200566012
## reached.threshold          0.0098841270585
## steps                  13350.0000000000000
## Intercept.to.1layhid1      3.3435231104655
## Input.to.1layhid1         -0.0326649028146
## Intercept.to.1layhid2     -1.0238568833332
## Input.to.1layhid2          0.0265849496975
## Intercept.to.1layhid3     -0.8297624813750
## Input.to.1layhid3          0.0333436126782
## Intercept.to.1layhid4     -1.9300149280192
## Input.to.1layhid4          0.1039925331423
## Intercept.to.1layhid5     -1.3097766428221
## Input.to.1layhid5          0.0251102639896
## Intercept.to.1layhid6      1.9133628293210
## Input.to.1layhid6         -0.0416349555337
## Intercept.to.1layhid7     -1.5671989218127
## Input.to.1layhid7          0.0252265498530
## Intercept.to.1layhid8      0.3673678601675
## Input.to.1layhid8         -0.2266382104158
## Intercept.to.1layhid9     -1.0027573168762
## Input.to.1layhid9          0.0261624491559
## Intercept.to.1layhid10   -25.5219059369510
## Input.to.1layhid10        13.9791880843293
## Intercept.to.Output        0.3631573092747
## 1layhid.1.to.Output       -0.8769227234988
## 1layhid.2.to.Output        1.4150924807060
## 1layhid.3.to.Output        1.8162786096676
## 1layhid.4.to.Output        1.5621092894428
## 1layhid.5.to.Output        1.6850193729260
## 1layhid.6.to.Output        0.5464951291680
## 1layhid.7.to.Output        2.9640115779034
## 1layhid.8.to.Output       -2.9564849836285
## 1layhid.9.to.Output        2.4067860122472
## 1layhid.10.to.Output       0.1486939056116
## 
## attr(,"class")
## [1] "nn"
```

```r
#Plot the neural network
plot(net.sqrt)
 
#Test the neural network on some training data
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
 
#See what properties net.sqrt has
ls(net.results)
```

```
## [1] "net.result" "neurons"
```

```r
#see the results
print(net.results$net.result)
```

```
##              [,1]
##  [1,] 1.117209699
##  [2,] 1.974547013
##  [3,] 2.999544839
##  [4,] 4.004906319
##  [5,] 4.991688329
##  [6,] 6.005628793
##  [7,] 6.998889399
##  [8,] 7.997251647
##  [9,] 9.008886091
## [10,] 9.976634736
```

```r
#Display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
                         as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```

```
##    Input Expected Output Neural Net Output
## 1      1               1       1.117209699
## 2      4               2       1.974547013
## 3      9               3       2.999544839
## 4     16               4       4.004906319
## 5     25               5       4.991688329
## 6     36               6       6.005628793
## 7     49               7       6.998889399
## 8     64               8       7.997251647
## 9     81               9       9.008886091
## 10   100              10       9.976634736
```

*Acknowledgement: this example excercise was from* http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/ 

